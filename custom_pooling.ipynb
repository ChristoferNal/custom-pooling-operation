{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Pooling Operation in Pytorch.\n",
    "\n",
    "The goal of this tutorial is to learn how to create a pooling operation from scratch. \n",
    "We implement max pooling in two different ways, using pytorch API in python and creating our own C++ extension. \n",
    "The two ways are compared against the native max pool op."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data - Cifar\n",
    "\n",
    "We use Cifar as our data set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from sklearn.metrics import f1_score\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.modules.utils import _pair, _quadruple\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR100(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=8)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR100(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Max Pool using pytorch in pure python.\n",
    "\n",
    "Reference: https://gist.github.com/rwightman/f2d3849281624be7c0f11c85c87c1598\n",
    "\n",
    "\n",
    "We use existing pytorch functions and tensor operations, which makes use of autograd. There is no need to implement the backpropagation as it comes free with autograd. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPool(nn.Module):\n",
    "\n",
    "    def __init__(self, kernel_size=3, stride=1, padding=0, same=False, timing=False):\n",
    "        super(MaxPool, self).__init__()\n",
    "        self.k = _pair(kernel_size)\n",
    "        self.stride = _pair(stride)\n",
    "        self.padding = _quadruple(padding)  # convert to l, r, t, b\n",
    "        self.same = same\n",
    "        self.timing = timing\n",
    "\n",
    "    def _padding(self, x):\n",
    "        if self.timing:\n",
    "            start = time.time()\n",
    "        if self.same:\n",
    "            ih, iw = x.size()[2:]\n",
    "            if ih % self.stride[0] == 0:\n",
    "                ph = max(self.k[0] - self.stride[0], 0)\n",
    "            else:\n",
    "                ph = max(self.k[0] - (ih % self.stride[0]), 0)\n",
    "            if iw % self.stride[1] == 0:\n",
    "                pw = max(self.k[1] - self.stride[1], 0)\n",
    "            else:\n",
    "                pw = max(self.k[1] - (iw % self.stride[1]), 0)\n",
    "            pl = pw // 2\n",
    "            pr = pw - pl\n",
    "            pt = ph // 2\n",
    "            pb = ph - pt\n",
    "            padding = (pl, pr, pt, pb)\n",
    "        else:\n",
    "            padding = self.padding\n",
    "        if self.timing:\n",
    "            print('_pad {}'.format(time.time() - start))\n",
    "        return padding\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.timing:\n",
    "            start = time.time()\n",
    "        x = F.pad(x, self._padding(x), mode='reflect')\n",
    "        if self.timing:\n",
    "            print('pad {}'.format(time.time() - start))\n",
    "            start = time.time()\n",
    "        x = x.unfold(2, self.k[0], self.stride[0]).unfold(3, self.k[1], self.stride[1])\n",
    "        if self.timing:\n",
    "            print('unfold {}'.format(time.time() - start))\n",
    "            start = time.time()\n",
    "            print('x.size()[:4] {}'.format(x.size()[:4] + (-1,)))\n",
    "        x = x.contiguous().view(x.size()[:4] + (-1,))\n",
    "        if self.timing:\n",
    "            print('view {}'.format(time.time() - start))\n",
    "            start = time.time()\n",
    "        pool, indices = torch.max(x, dim=-1)        \n",
    "        if self.timing:\n",
    "            print('max {}'.format(time.time() - start))\n",
    "        \n",
    "        return pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max Pool as a C++ extension.\n",
    "\n",
    "In order to create a C++ extension you need the following files:\n",
    "- pooling.cpp which has the C++ (pytorch API) implementation of your custom operation. At the end of this file you also need to declare a python binder as follows: \n",
    "\n",
    "    PYBIND11_MODULE(TORCH_EXTENSION_NAME, m) {\n",
    "      m.def(\"max_pool\", &max_pool, \"CPPPool max_pool\");\n",
    "    }\n",
    "\n",
    "- setup.py which is responsible for creating the python extension. From command line and after installing the C++ version of pytorch run the following command: python setup.py install\n",
    "\n",
    "The c++ implementation includes two different functions in pooling.cpp named 'max_pool' and 'same_padding'.\n",
    "A more efficient implementation would be to create an operation from scratch at Cuda level, but that would require handling the backpropagation as well.\n",
    "\n",
    "MaxPoolCpp implements our python wrapper calling the C++ extension.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pooling_cpp\n",
    "\n",
    "class MaxPoolCpp(nn.Module):\n",
    "\n",
    "    def __init__(self, kernel_size=3, stride=1, padding=0, same=False):\n",
    "        super(MaxPoolCpp, self).__init__()\n",
    "        self.k = _pair(kernel_size)\n",
    "        self.stride = _pair(stride)\n",
    "        self.padding = _quadruple(padding)  # convert to l, r, t, b\n",
    "        self.same = same\n",
    "    \n",
    "    def forward(self, x):\n",
    "        pool = pooling_cpp.max_pool(x, 2, torch.tensor(list(self.k)), torch.tensor(list(self.stride)), self.same, list(self.padding))        \n",
    "        return pool\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading images and placing them in a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "torch.Size([50000, 32, 32, 3])\n"
     ]
    }
   ],
   "source": [
    "print(trainset.train_data.shape)  \n",
    "imgs = trainset.train_data\n",
    "imgs = torch.Tensor(imgs)\n",
    "print(imgs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating pure pooling performance.\n",
    "\n",
    "The following code applies pure pooling operation on the images from cifar and evaluates native, custom (python) and cpp versions of pooling. \n",
    "The two main functions are test_pool_results and test_pool_perf. The former compares the results of two pooling operations validating our custom implementations. The latter one measures the time that it takes to apply max pooling on the given data. Some representative results are: native 0.519s, custom 1.217s, cpp 1.227s. \n",
    "\n",
    "The custom model implemented in pure python doesn't differ from the C++ implementation in terms of performance. Sometimes the cpp version can also be slightly slower, but the difference is minor. Max pooling is a simple operation and this might change for more complicated ones. \n",
    "\n",
    "Comparing against the native model (which is implemented in Cuda) we see that it is more than 2 times faster: custom/native time: 2.35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Comparing native vs custom: 1\n",
      "Comparing native vs cpp: 1\n",
      "\n",
      "native 0.5481758673985799\n",
      "custom 1.29437153339386\n",
      "cpp 1.2856293042500815\n",
      "custom/native time: 2.36\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "def test_pool_results(pool1, pool2, name1, name2, img):\n",
    "    are_equal = torch.all(torch.eq(pool1, pool2))\n",
    "    print(\"Comparing {} vs {}: {}\".format(name1, name2, are_equal))\n",
    "    return are_equal\n",
    "\n",
    "def test_pool_perf(pool, name, img, device):\n",
    "    start = time.time()\n",
    "    pool.to(device)\n",
    "    result = pool(img)\n",
    "    duration = time.time() - start\n",
    "    return duration, result\n",
    "\n",
    "native_dur = list()\n",
    "custom_dur = list()\n",
    "cpp_dur = list()\n",
    "for i in range(0, 30):\n",
    "    img = imgs\n",
    "    dur, native = test_pool_perf(nn.MaxPool2d(2, 2), 'native', img, device)\n",
    "    native_dur.append(dur)\n",
    "    dur, custom = test_pool_perf(MaxPool(2, 2), 'custom', img, device)\n",
    "    custom_dur.append(dur)\n",
    "    dur, cpp = test_pool_perf(MaxPoolCpp(2, 2), 'cpp', img, device)\n",
    "    cpp_dur.append(dur)\n",
    "\n",
    "test_pool_results(native, custom, 'native', 'custom', img)\n",
    "test_pool_results(native, cpp, 'native', 'cpp', img)\n",
    "\n",
    "avg = lambda x: sum(x)/len(x)\n",
    "\n",
    "print('\\nnative {}'.format(avg(native_dur)))\n",
    "print('custom {}'.format(avg(custom_dur)))\n",
    "print('cpp {}'.format(avg(cpp_dur)))\n",
    "print('custom/native time: {}'.format(round(avg(custom_dur)/avg(native_dur), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance evaluation using a small neural network with 2 pooling operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSTOM = 'custom'\n",
    "NATIVE = 'native'\n",
    "CPP = 'cpp'\n",
    "\n",
    "class Net2Pool(nn.Module):\n",
    "    def __init__(self, num_classes=10, pooling=NATIVE):\n",
    "        super(Net2Pool, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 50, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(50, 50, 5, 1)\n",
    "        \n",
    "        if pooling is NATIVE:\n",
    "            self.pool = nn.MaxPool2d(2, 2)\n",
    "        elif pooling is CUSTOM:\n",
    "            self.pool = MaxPool(2, 2)\n",
    "        elif pooling is CPP:\n",
    "            self.pool = MaxPoolCpp(2, 2)\n",
    "      \n",
    "        self.fc1 = nn.Linear(5*5*50, 500)\n",
    "        self.fc2 = nn.Linear(500, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = x.view(-1, 5*5*50)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "def configure_net(net, device):\n",
    "    net.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "    return net, optimizer, criterion\n",
    "\n",
    "def train(net, optimizer, criterion, trainloader, device, epochs=10, logging=2000):\n",
    "    for epoch in range(epochs):  \n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            start = time.time()\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if i % logging == logging - 1:    \n",
    "                print('[%d, %5d] loss: %.3f duration: %.5f' %\n",
    "                      (epoch + 1, i + 1, running_loss / logging, time.time() - start))\n",
    "                running_loss = 0.0\n",
    "                \n",
    "    print('Finished Training')\n",
    "\n",
    "def test(net, testloader, device):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    predictions = []\n",
    "    l = []\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            predictions.extend(predicted.cpu().numpy())\n",
    "            l.extend(labels.cpu().numpy())\n",
    "\n",
    "\n",
    "    print('Accuracy: {}'.format(100 * correct / total))\n",
    "    print('Micro {}'.format(f1_score(l, predictions, average='micro')))\n",
    "    print('Macro {}'.format(f1_score(l, predictions, average='macro')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance evaluation results\n",
    "\n",
    "The performance evaluation is 2-fold. It compares the **training time** of the neural network and the **inference time** for each of the three pooling operations.\n",
    "\n",
    "The average training time per epoch for each pooling are:\n",
    "_native_ = 27\n",
    "_custom_ = 41\n",
    "_cpp_ = 38\n",
    "\n",
    "These results can vary and in general the **custom and cpp model are almost equivalent**. The neural net using the native max pool was the fastest one, with training duration around half the time.\n",
    "\n",
    "Regarding inference time, the difference is not very significant. e.g. native = 4.34, custom = 4.70, cpp = 4.68."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Finished Training\n",
      "Average training time per epoch of native: 32.15662657022476\n",
      "Accuracy: 31.11\n",
      "Micro 0.3111\n",
      "Macro 0.31087129648577155\n",
      "Testing time of native: 4.227973461151123\n",
      "Finished Training\n",
      "Average training time per epoch of custom: 41.62029505968094\n",
      "Accuracy: 32.24\n",
      "Micro 0.3224\n",
      "Macro 0.32243667860463615\n",
      "Testing time of custom: 5.201342821121216\n",
      "Finished Training\n",
      "Average training time per epoch of cpp: 42.65701643228531\n",
      "Accuracy: 30.77\n",
      "Micro 0.3077\n",
      "Macro 0.30209508676358354\n",
      "Testing time of cpp: 6.22520899772644\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "LOGGING = 15000\n",
    "NUM_CLASSES = 100\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)\n",
    "\n",
    "def measure_training_time(pooling):\n",
    "    net, optimizer, criterion = configure_net(Net2Pool(num_classes=NUM_CLASSES, pooling=pooling), device)\n",
    "    start = time.time()\n",
    "    train(net, optimizer, criterion, trainloader, DEVICE, epochs=EPOCHS, logging=LOGGING)\n",
    "    print('Average training time per epoch of {}: {}'.format(pooling, (time.time() - start)/EPOCHS))\n",
    "    start = time.time()\n",
    "    test(net, testloader, device)\n",
    "    print('Testing time of {}: {}'.format(pooling, time.time() - start))\n",
    "    \n",
    "measure_training_time(NATIVE)\n",
    "measure_training_time(CUSTOM)\n",
    "measure_training_time(CPP)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
